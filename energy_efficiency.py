# -*- coding: utf-8 -*-
"""energy_efficiency.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-WOGDJCA2EZs2SFyQN9O9PIaUJA1p5zA

<h1 align=center><font size = 5>Building Model to Predict Heating and Cooling Load</font></h1>

<br>

<img src="https://raw.githubusercontent.com/doguilmak/Predict-Heating-and-Cooling-Load/main/assets/asset_1.png" height=500 width = 1000 alt="energy">

<small>Picture Source: <a href="https://github.com/doguilmak">Doğu İlmak</a></small>

<br>

<h2>Data Set Information:</h2>

<p>We perform energy analysis using <i>12</i> different building shapes simulated in <i>Ecotect</i>. The buildings differ with respect to the <i>glazing area</i>, <i>the glazing area distribution</i>, and the <i>orientation</i>, amongst other parameters. We simulate various settings as functions of the <i>afore-mentioned</i> characteristics to obtain <i>768 building shapes</i>. The dataset comprises <i>768</i> samples and <i>8</i> features, aiming to predict <i>two real valued responses</i>. It can also be used as a <i>multi-class classification problem</i> if the response is rounded to the nearest integer. <b>All the informations about data set referred from <a href='https://archive.ics.uci.edu/ml/datasets/Energy+efficiency'>archive.ics.uci.edu</a>.</b></p>

<br>

<h2>Source</h2>

The dataset was created by <b>Angeliki Xifara</b> (angxifara@gmail.com, Civil/Structural Engineer) and was processed by <b>Athanasios Tsanas</b> (tsanasthanasis@gmail.com, <i>Oxford Centre for Industrial and Applied Mathematics, University of Oxford, UK</i>).

<br>

<h2>Objectives</h2>

<ul>
	<li>Understand the data set & cleanup (data pre-processing).</li>
	<li>Build <i>Multi-output</i> model to predict heating and cooling load. Afterwards, evaluate the model.</li>
</ul> 


<br>

<h2>Attribute Information</h2>

<p>The dataset contains eight attributes (or features, denoted by X1...X8) and two responses (or outcomes, denoted by y1 and y2). <b>The aim is to use the eight features to predict each of the two responses.</b></p>

<ol>
  <li>X1 Relative Compactness</li>
  <li>X2 Surface Area</li>
  <li>X3 Wall Area</li>
  <li>X4 Roof Area</li>
  <li>X5 Overall Height</li>
  <li>X6 Orientation</li>
  <li>X7 Glazing Area</li>
  <li>X8 Glazing Area Distribution</li>
  <li><b>Output variables: </b><ol>
  <li><i>y1 Heating Load</i></li>
  <li><i>y2 Cooling Load</i></li>
  </ol></li>
</ol>

<br>

<h2>Keywords</h2>
<ul>
  <li>Neural Networks</li>
  <li>Energy Efficiency</li>
  <li>Regression</li>
  <li>Computer Science</li>
	<li>Deep Learning</li>
</ul>

<br>

<h2>Table of Contents</h2>

<p>This study looked into assessing the heating load and cooling load requirements of buildings (that is, energy efficiency) as a function of building parameters. In following contents, you can see the process and steps of the model architecture.</p>

<div class="alert alert-block alert-info" style="margin-top: 20px">
<li><a href="https://#import">Import Libraries and Building Functions for Model</a></li>
<li><a href="https://#data_preparation">Dataset Preparation (Data Preprocessing)</a></li>
<li><a href="https://#compile_fit">Build and Fit the Model</a></li>
<li><a href="https://#analize_model">Analize the Model</a></li>
<li><a href="https://#revelant_papers">Relevant Papers</a></li>
<li><a href="https://#citation_request">Citation Request</a></li>

<br>

<p></p>
Estimated Time Needed: <strong>20 min</strong>
</div>

<br>
<h2 align=center id="import">Import Libraries and Building Functions for Model</h2>
<p>The following are the libraries we are going to use for this lab:</p>
"""

try:
  # %tensorflow_version only exists in Colab.
  get_ipython().run_line_magic('tensorflow_version', '2.x')
except Exception:
  pass

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import os
import datetime
import math

from tensorflow.keras.callbacks import TensorBoard, CSVLogger
get_ipython().run_line_magic('load_ext', 'tensorboard')
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Input

from sklearn.model_selection import train_test_split

from keras.models import load_model

def format_output(data):
    y1 = data.pop('heating_load')
    y1 = np.array(y1)
    y2 = data.pop('cooling_load')
    y2 = np.array(y2)
    return y1, y2

"""<p>Normalization function:</p>

$$x_{norm} = \frac{x - \mu}{\sigma}$$
"""

def norm(x):
    return (x - train_stats['mean']) / train_stats['std']

def plot_diff(y_true, y_pred, title=''):
  plt.figure(figsize = (18, 12))
  plt.scatter(y_true, y_pred)
  plt.title(title)
  plt.xlabel('True Values')
  plt.ylabel('Predictions')
  plt.axis('equal')
  plt.axis('square')
  plt.xlim(plt.xlim())
  plt.ylim(plt.ylim())
  plt.plot([-100, 100], [-100, 100])
  plt.show()

"""<br>
<h2 align=center id="data_preparation">Dataset Preparation (Data Preprocessing)</h2>
"""

!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx

URI = '/content/ENB2012_data.xlsx'

df = pd.read_excel(URI)
df = df.sample(frac=1).reset_index(drop=True)

df.columns = ['rel_compactness', 'surface_area', 'wall_area', 'roof_area', 'overall_height', 'orientation', 'glazing_area', 'glazing_area_dist', 'heating_load', 'cooling_load']
df

print("Number of NaN values: {}.".format(df.isnull().sum().sum()))

print("Number of duplicated rows: {}.".format(df.duplicated().sum()))

"""<p>We have 0 duplicated rows and 0 NaN values. So, we don't have to modify our data (drop NaN values or duplicated rows).</p>"""

df.describe().T

df.info()

mask = np.triu(np.ones_like(df.corr()))
plt.figure(figsize = (20, 20))
sns.heatmap(df.corr(), mask=mask, annot=True, cmap="Blues")

df.corr()

"""<h3>Test Train Split</h3>

<p>Creating train and test dataset Train/Test Split involves splitting the dataset into training and testing sets respectively, which are mutually exclusive. After which, you train with the training set and test with the testing set. This will provide a more accurate evaluation on out-of-sample accuracy because the testing dataset is not part of the dataset that have been used to train the model. Therefore, it gives us a better understanding of how well our model generalizes on new data. We know the outcome of each data point in the testing dataset, making it great to test with! Since this data has not been used to train the model, the model has no knowledge of the outcome of these data points. So, in essence, it is truly an out-of-sample testing. Let's split our dataset into train and test sets. Around <i>80%</i> of the entire dataset will be used for training and <i>20%<i> for testing.</p>

"""

train, test = train_test_split(df, test_size=0.2, random_state = 1)
train, val = train_test_split(train, test_size=0.2, random_state = 1)

train_stats = train.describe()

train.shape

test.shape

val.shape

train_stats.pop('heating_load')
train_stats.pop('cooling_load')
train_stats = train_stats.transpose()

train_Y = format_output(train)
test_Y = format_output(test)
val_Y = format_output(val)

"""<p>Now, we need to normalize the our dataset with the <code>norm</code> function that we created.</p>"""

norm_train_X = norm(train)
norm_test_X = norm(test)
norm_val_X = norm(val)

"""<p>For an instance, let's take a look at <code>norm_train_X</code> dataframe:</p>"""

norm_train_X.head()

norm_test_X.head()

norm_val_X.head()

"""<br>
<h2 align=center id="build_fit_model">Build and Fit the Model</h2>
"""

LR = 0.0001 #@param {type:"number"}
EPOCHS = 256 #@param {type:"number"}
BATCH_SIZE = 32 #@param {type:"integer"}
INDEPENDENT_VARIABLES = len(train.columns)
rms = tf.keras.optimizers.RMSprop(lr=LR)

def base_model(input_shape, repetitions): 
  input_ = tf.keras.layers.Input(shape=(input_shape,), name='input')
  x = input_
  
  for i in range(repetitions):
    n_filters = 2**(4 + i)
    x = Dense(n_filters, activation='relu', name=f'base_dense_{i}')(x)

  return x, input_


def final_model(input_shape, repetitions):
    
    x, input_ = base_model(input_shape, repetitions)

    heating_load = Dense(units='1', name='heating_load')(x)
    cooling_load = Dense(units='1', name='cooling_load')(x)

    model = Model(inputs=input_, outputs=[heating_load, cooling_load])

    print(model.summary())
    return model

"""<p>You can use the weights builded by myself. For that, please uncomment the following code line:</p>"""

#model = load_model('/content/model.h5')

model = final_model(INDEPENDENT_VARIABLES, 5)

from tensorflow.keras.utils import plot_model
plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')

get_ipython().system('rm -rf logs')

model.compile(optimizer=rms,
            loss = {'heating_load' : 'mean_squared_error',
                  'cooling_load' : 'mean_squared_error'
                 },
            metrics = {'heating_load' : tf.keras.metrics.RootMeanSquaredError(),
                     'cooling_load': tf.keras.metrics.RootMeanSquaredError()
                   }
            )

logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir)

csv_file = 'training.csv'

model.fit(norm_train_X, train_Y,
                    epochs = EPOCHS, validation_data=(norm_val_X, val_Y),
                    callbacks=[tensorboard_callback, CSVLogger(csv_file)])

!mkdir -p saved_model
model.save('saved_model/my_model')

model.save('saved_model/last_model.h5')

"""<br>
<h2 align=center id="analize_model">Analize the Model</h2>
"""

get_ipython().run_line_magic('tensorboard', '--logdir logs')

pd.read_csv(csv_file).head(10)

predictions = model.predict(norm_test_X)
predictions

test_Y

plot_diff(test_Y[0], predictions[0], title='Heating Load')
plot_diff(test_Y[1], predictions[1], title='Cooling Load')

"""<br>
<h2 align=center id="revelant_papers">Relevant Papers</h2>

<ul>
  <li><b>A. Tsanas, A. Xifara: 'Accurate quantitative estimation of energy performance of residential buildings using statistical machine learning tools'</b>, Energy and Buildings, Vol. 49, pp. 560-567, 2012</li>
  <br>
</ul>

<h2 align=center id="citation_request">Citation Request</h2>

<ul>
  <li><b>A. Tsanas, A. Xifara: 'Accurate quantitative estimation of energy performance of residential buildings using statistical machine learning tools'</b>, Energy and Buildings, Vol. 49, pp. 560-567, 2012</li>

  <li>For further details on the data analysis methodology:
  <b>A. Tsanas, 'Accurate telemonitoring of Parkinson's disease symptom severity using nonlinear speech signal processing and statistical machine learning'</b>, D.Phil. thesis, University of Oxford, 2012</li>
</ul>


<br>

<h1>Contact Me</h1>
<p>If you have something to say to me please contact me:</p>

<ul>
  <li>Twitter: <a href="https://twitter.com/Doguilmak">Doguilmak</a></li>
  <li>Mail address: doguilmak@gmail.com</li>
</ul>
"""

from datetime import datetime
print(f"Changes have been made to the project on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")